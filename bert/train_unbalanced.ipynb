{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"title":"In [1]:","trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (23.2.1)\n","Collecting pip\n","  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/25/49/2255373efd193c6fbd97dc22399e9c830a6517a0f02ca77fbc0bd83ac5cc/pip-24.1-py3-none-any.whl.metadata\n","  Downloading pip-24.1-py3-none-any.whl.metadata (3.6 kB)\n","Downloading pip-24.1-py3-none-any.whl (1.8 MB)\n","   ---------------------------------------- 1.8/1.8 MB 2.3 MB/s eta 0:00:00\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: To modify pip, please run the following command:\n","C:\\Users\\chisa\\miniconda3\\envs\\nomi3\\python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting comet_ml\n","  Obtaining dependency information for comet_ml from https://files.pythonhosted.org/packages/f9/d0/1148ff56795e6dbcc86d5953341d39d5fbba52bcb23330fb765ca8492124/comet_ml-3.43.2-py3-none-any.whl.metadata\n","  Downloading comet_ml-3.43.2-py3-none-any.whl.metadata (3.9 kB)\n","Collecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n","  Obtaining dependency information for everett[ini]<3.2.0,>=1.0.1 from https://files.pythonhosted.org/packages/91/9a/d882fd7562208456236fb2e62b762bf16fbc9ecde842bb871f676ca0f7e1/everett-3.1.0-py2.py3-none-any.whl.metadata\n","  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from comet_ml) (4.17.3)\n","Requirement already satisfied: psutil>=5.6.3 in c:\\users\\chisa\\appdata\\roaming\\python\\python310\\site-packages (from comet_ml) (5.9.4)\n","Collecting python-box<7.0.0 (from comet_ml)\n","  Obtaining dependency information for python-box<7.0.0 from https://files.pythonhosted.org/packages/69/97/e43a8ab4487f923356a0ab8b0e540448aa453a8ec9314d49dd2098952185/python_box-6.1.0-cp310-cp310-win_amd64.whl.metadata\n","  Downloading python_box-6.1.0-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n","Collecting requests-toolbelt>=0.8.0 (from comet_ml)\n","  Obtaining dependency information for requests-toolbelt>=0.8.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: requests>=2.18.4 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from comet_ml) (2.31.0)\n","Collecting semantic-version>=2.8.0 (from comet_ml)\n","  Obtaining dependency information for semantic-version>=2.8.0 from https://files.pythonhosted.org/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl.metadata\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting sentry-sdk>=1.1.0 (from comet_ml)\n","  Obtaining dependency information for sentry-sdk>=1.1.0 from https://files.pythonhosted.org/packages/c2/ab/522cf99db4905094a6e0ae6e2661a2a9e4890a1d3991b5bf45e206637721/sentry_sdk-2.6.0-py2.py3-none-any.whl.metadata\n","  Downloading sentry_sdk-2.6.0-py2.py3-none-any.whl.metadata (10 kB)\n","Collecting simplejson (from comet_ml)\n","  Obtaining dependency information for simplejson from https://files.pythonhosted.org/packages/7f/60/b0071b60e9318bb5c3716e5c0d506d61350670b7fba9a8532ebf3959b88a/simplejson-3.19.2-cp310-cp310-win_amd64.whl.metadata\n","  Downloading simplejson-3.19.2-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n","Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from comet_ml) (1.26.16)\n","Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from comet_ml) (1.14.1)\n","Collecting wurlitzer>=1.0.2 (from comet_ml)\n","  Obtaining dependency information for wurlitzer>=1.0.2 from https://files.pythonhosted.org/packages/9a/24/93ce54550a9dd3fd996ed477f00221f215bf6da3580397fbc138d6036e2e/wurlitzer-3.1.1-py3-none-any.whl.metadata\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n","  Obtaining dependency information for dulwich!=0.20.33,>=0.20.6 from https://files.pythonhosted.org/packages/3d/6b/f8aa44ec32016f20bb4f203ce686a8591fd51fcf1ccbdad9227ba0b054b2/dulwich-0.22.1-cp310-cp310-win_amd64.whl.metadata\n","  Downloading dulwich-0.22.1-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n","Collecting rich>=13.3.2 (from comet_ml)\n","  Obtaining dependency information for rich>=13.3.2 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n","  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Obtaining dependency information for configobj from https://files.pythonhosted.org/packages/d3/bb/d10e531b297dd1d46f6b1fd11d018247af9f2d460037554bb7bb9011c6ac/configobj-5.0.8-py2.py3-none-any.whl.metadata\n","  Downloading configobj-5.0.8-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: attrs>=17.4.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2023.7.22)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from rich>=13.3.2->comet_ml) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chisa\\appdata\\roaming\\python\\python310\\site-packages (from rich>=13.3.2->comet_ml) (2.13.0)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.0)\n","Requirement already satisfied: six in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n","Downloading comet_ml-3.43.2-py3-none-any.whl (677 kB)\n","   -------------------------------------- 677.4/677.4 kB 318.6 kB/s eta 0:00:00\n","Downloading dulwich-0.22.1-cp310-cp310-win_amd64.whl (600 kB)\n","   -------------------------------------- 600.6/600.6 kB 995.6 kB/s eta 0:00:00\n","Downloading python_box-6.1.0-cp310-cp310-win_amd64.whl (962 kB)\n","   ---------------------------------------- 962.3/962.3 kB 1.3 MB/s eta 0:00:00\n","Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","   ---------------------------------------- 54.5/54.5 kB 470.6 kB/s eta 0:00:00\n","Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n","   ---------------------------------------- 240.7/240.7 kB 1.2 MB/s eta 0:00:00\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading sentry_sdk-2.6.0-py2.py3-none-any.whl (296 kB)\n","   -------------------------------------- 296.1/296.1 kB 609.5 kB/s eta 0:00:00\n","Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading simplejson-3.19.2-cp310-cp310-win_amd64.whl (75 kB)\n","   ---------------------------------------- 75.5/75.5 kB 693.9 kB/s eta 0:00:00\n","Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n","Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n","Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, rich, requests-toolbelt, comet_ml\n","Successfully installed comet_ml-3.43.2 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 rich-13.7.1 semantic-version-2.10.0 sentry-sdk-2.6.0 simplejson-3.19.2 wurlitzer-3.1.1\n","Collecting scikit-plot\n","  Obtaining dependency information for scikit-plot from https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl.metadata\n","  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from scikit-plot) (3.7.1)\n","Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from scikit-plot) (1.3.0)\n","Requirement already satisfied: scipy>=0.9 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from scikit-plot) (1.10.1)\n","Requirement already satisfied: joblib>=0.10 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from scikit-plot) (1.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.0.5)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\chisa\\miniconda3\\envs\\nomi3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n","Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n","Installing collected packages: scikit-plot\n","Successfully installed scikit-plot-0.3.7\n"]}],"source":["!pip install --upgrade pip\n","!pip install comet_ml\n","!pip install -q pyyaml h5py\n","!pip install scikit-plot"]},{"cell_type":"markdown","metadata":{},"source":["## Initial Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [2]:","trusted":false},"outputs":[],"source":["# Import libraries\n","from comet_ml import Experiment\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","import seaborn as sns\n","import scikitplot as skplt\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import initializers\n","from transformers import DistilBertTokenizerFast\n","from transformers import TFDistilBertModel, DistilBertConfig\n","\n","# Import utility functions\n","from src.utils.train_utils import batch_encode\n","from src.utils.train_utils import focal_loss\n","\n","# Import matplotlib\n","pd.plotting.register_matplotlib_converters()\n","import matplotlib.pyplot as plt\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","\n","\n","\n","# Load training data\n","X_train = pd.read_csv('data/processed/unbalanced_dataset/X_train.csv')['comment_text']\n","X_valid = pd.read_csv('data/processed/unbalanced_dataset/X_valid.csv')['comment_text']\n","y_train = pd.read_csv('data/processed/unbalanced_dataset/y_train.csv')['isToxic']\n","y_valid = pd.read_csv('data/processed/unbalanced_dataset/y_valid.csv')['isToxic']\n","\n","# Load test data\n","test = pd.read_csv('data/processed/test_merged.csv')\n","X_test = test['comment_text']\n","y_test = test['isToxic']\n","\n","# Check data\n","print('Our training data has   ', len(X_train.index), ' rows.')\n","print('Our validation data has ', len(X_valid.index), ' rows.')\n","print('Our test data has       ', len(X_test.index), ' rows.')\n","\n","\n","\n","# Allow us to see full text (not truncated)\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"markdown","metadata":{},"source":["## Set Up Comet.ml Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [3]:","trusted":false},"outputs":[],"source":["# Create an experiment with your api key:\n","experiment = Experiment(\n","    api_key=\"YOUR_API_KEY\",\n","    project_name=\"YOUR_PROJECT_NAME\",\n","    workspace=\"YOUR_WORKSPACE\",\n","    auto_histogram_weight_logging=True,\n","    auto_histogram_gradient_logging=True,\n","    auto_histogram_activation_logging=True,\n","    auto_log_co2=True,\n","    log_env_details=True,\n","    log_env_gpu=True,\n","    log_env_cpu=True\n",")\n","\n","# Set parameters:\n","params = {'MAX_LENGTH': 128,\n","          'EPOCHS': 6,\n","          'LEARNING_RATE': 5e-5,\n","          'FT_EPOCHS': 2,\n","          'OPTIMIZER': 'adam',\n","          'FL_GAMMA': 2.0,\n","          'FL_ALPHA': 0.2,\n","          'BATCH_SIZE': 64,\n","          'NUM_STEPS': len(X_train.index) // 64,\n","          'DISTILBERT_DROPOUT': 0.2,\n","          'DISTILBERT_ATT_DROPOUT': 0.2,\n","          'LAYER_DROPOUT': 0.2,\n","          'KERNEL_INITIALIZER': 'GlorotNormal',\n","          'BIAS_INITIALIZER': 'zeros',\n","          'POS_PROBA_THRESHOLD': 0.5,          \n","          'ADDED_LAYERS': 'Dense 256, Dense 32, Dropout 0.2',\n","          'LR_SCHEDULE': '5e-5 for 6 epochs, Fine-tune w/ adam for 2 epochs @2e-5',\n","          'FREEZING': 'All DistilBERT layers frozen for 6 epochs, then unfrozen for 2',\n","          'CALLBACKS': '[early_stopping w/ patience=0]',\n","          'RANDOM_STATE':42\n","          }\n","\n","\n","# Log parameters\n","experiment.log_parameters(params)\n","\n","# Log data assets\n","experiment.log_asset('data/processed/test_merged.csv')\n","experiment.log_asset_folder('data/processed/unbalanced_dataset')\n","experiment.log_dataset_info(name='Toxic Comment (Unbalanced)')"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [5]:","trusted":false},"outputs":[],"source":["########## Ensure reproducibility ##########\n","\n","\n","# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n","os.environ['PYTHONHASHSEED']=str(params['RANDOM_STATE'])\n","\n","# 2. Set `python` built-in pseudo-random generator at a fixed value\n","random.seed(params['RANDOM_STATE'])\n","\n","# 3. Set `numpy` pseudo-random generator at a fixed value\n","np.random.seed(params['RANDOM_STATE'])\n","\n","# 4. Set `tensorflow` pseudo-random generator at a fixed value\n","tf.random.set_seed(seed=params['RANDOM_STATE'])"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenize text"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [6]:","trusted":false},"outputs":[],"source":["# Instantiate DistilBERT tokenizer...we use the Fast version to optimize runtime\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","# Encode X_train\n","X_train_ids, X_train_attention = batch_encode(tokenizer, X_train.tolist())\n","\n","# Encode X_valid\n","X_valid_ids, X_valid_attention = batch_encode(tokenizer, X_valid.tolist())\n","\n","# Encode X_test\n","X_test_ids, X_test_attention = batch_encode(tokenizer, X_test.tolist())\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["## Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [9]:","trusted":false},"outputs":[],"source":["def build_model(transformer, max_length=params['MAX_LENGTH']):\n","    \"\"\"\"\"\"\"\"\"\n","    Template for building a model off of the BERT or DistilBERT architecture\n","    for a binary classification task.\n","    \n","    Input:\n","      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n","                      with no added classification head attached.\n","      - max_length:   integer controlling the maximum number of encoded tokens \n","                      in a given sequence.\n","    \n","    Output:\n","      - model:        a compiled tf.keras.Model with added classification layers \n","                      on top of the base pre-trained model architecture.\n","    \"\"\"\"\"\"\"\"\"\"\n","    \n","    # Define weight initializer with a random seed to ensure reproducibility\n","    weight_initializer = tf.keras.initializers.GlorotNormal(seed=params['RANDOM_STATE']) \n","    \n","    # Define input layers\n","    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                            name='input_ids', \n","                                            dtype='int32')\n","    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                                  name='input_attention', \n","                                                  dtype='int32')\n","    \n","    # DistilBERT outputs a tuple where the first element at index 0\n","    # represents the hidden-state at the output of the model's last layer.\n","    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n","    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n","    \n","    # We only care about DistilBERT's output for the [CLS] token, which is located\n","    # at index 0.  Splicing out the [CLS] tokens gives us 2D data.\n","    cls_token = last_hidden_state[:, 0, :]\n","    \n","    D1 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(cls_token)\n","    \n","    X = tf.keras.layers.Dense(256,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D1)\n","    \n","    D2 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    X = tf.keras.layers.Dense(32,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D2)\n","    \n","    D3 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    # Define a single node that makes up the output layer (for binary classification)\n","    output = tf.keras.layers.Dense(1, \n","                                   activation='sigmoid',\n","                                   kernel_initializer=weight_initializer,  # CONSIDER USING CONSTRAINT\n","                                   bias_initializer='zeros'\n","                                   )(D3)\n","    \n","    # Define the model\n","    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n","    \n","    # Compile the model\n","    model.compile(tf.keras.optimizers.Adam(lr=params['LEARNING_RATE']), \n","                  loss=focal_loss(),\n","                  metrics=['accuracy'])\n","    \n","    return model\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"outputs":[],"source":["# The bare, pre-trained DistilBERT transformer model outputting raw hidden-states \n","# and without any specific head on top.\n","config = DistilBertConfig(dropout=params['DISTILBERT_DROPOUT'], \n","                          attention_dropout=params['DISTILBERT_ATT_DROPOUT'], \n","                          output_hidden_states=True)\n","distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n","\n","# Freeze DistilBERT layers to preserve pre-trained weights \n","for layer in distilBERT.layers:\n","    layer.trainable = False\n","\n","# Build model\n","model = build_model(distilBERT)"]},{"cell_type":"markdown","metadata":{},"source":["## Train Weights of Added Layers and Classification Head"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [10]:","trusted":false},"outputs":[],"source":["# Define callbacks\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                  mode='min',\n","                                                  min_delta=0,\n","                                                  patience=0,\n","                                                  restore_best_weights=True)\n","\n","# Train the model\n","train_history1 = model.fit(\n","    x = [X_train_ids, X_train_attention],\n","    y = y_train.to_numpy(),\n","    epochs = params['EPOCHS'],\n","    batch_size = params['BATCH_SIZE'],\n","    steps_per_epoch = params['NUM_STEPS'],\n","    validation_data = ([X_valid_ids, X_valid_attention], y_valid.to_numpy()),\n","    callbacks=[early_stopping],\n","    verbose=2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Unfreeze DistilBERT and Fine-tune All Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [12]:","trusted":false},"outputs":[],"source":["# Unfreeze DistilBERT weights to enable fine-tuning\n","for layer in distilBERT.layers:\n","    layer.trainable = True\n","\n","# Lower the learning rate to prevent destruction of pre-trained weights\n","optimizer = tf.keras.optimizers.Adam(lr=2e-5)\n","\n","# Recompile model after unfreezing\n","model.compile(optimizer=optimizer, \n","              loss=focal_loss(),\n","              metrics=['accuracy'])\n","\n","# Train the model\n","train_history2 = model.fit(\n","    x = [X_train_ids, X_train_attention],\n","    y = y_train.to_numpy(),\n","    epochs = params['FT_EPOCHS'],\n","    batch_size = params['BATCH_SIZE'],\n","    steps_per_epoch = params['NUM_STEPS'],\n","    validation_data = ([X_valid_ids, X_valid_attention], y_valid.to_numpy()),\n","    callbacks=[early_stopping],\n","    verbose=2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Model Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [17]:","trusted":false},"outputs":[],"source":["with experiment.test():\n","    # Generate predictions\n","    y_pred = model.predict([X_test_ids, X_test_attention])\n","    y_pred_thresh = np.where(y_pred >= params['POS_PROBA_THRESHOLD'], 1, 0)\n","    \n","    # Get evaluation results\n","    accuracy = accuracy_score(y_test, y_pred_thresh)\n","    auc_roc = roc_auc_score(y_test, y_pred)\n","    \n","    # Log evaluation metrics\n","    experiment.log_metrics({'Accuracy':accuracy, 'AUC-ROC':auc_roc})\n","    \n","    # Log the ROC curve\n","    fpr, tpr, thresholds = roc_curve(y_test.to_numpy(), y_pred)\n","    experiment.log_curve('ROC cuve', fpr, tpr)\n","\n","\n","print('Accuracy:  ', accuracy)   # 0.9218\n","print('ROC-AUC:   ', auc_roc)    # 0.9691"]},{"cell_type":"markdown","metadata":{},"source":["## Plot Training and Validation Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"outputs":[],"source":["# Build train_history\n","history_df1 = pd.DataFrame(train_history1.history)\n","history_df2 = pd.DataFrame(train_history2.history)\n","history_df = history_df1.append(history_df2, ignore_index=True)\n","\n","# Plot training and validation loss over each epoch\n","history_df.loc[:, ['loss', 'val_loss']].plot()\n","plt.title(label='Training + Validation Loss Over Time', fontsize=17, pad=19)\n","plt.xlabel('Epoch', labelpad=14, fontsize=14)\n","plt.ylabel('Focal Loss', labelpad=16, fontsize=14)\n","print(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n","\n","# Save figure\n","plt.savefig('figures/unbalanced_trainvalloss.png', dpi=300.0, transparent=True)\n","\n","# Log the figure\n","experiment.log_image('figures/unbalanced_trainvalloss.png', name='Train Validation Loss')"]},{"cell_type":"markdown","metadata":{},"source":["## Plot the Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"title":"In [18]:","trusted":false},"outputs":[],"source":["# Plot confusion matrix\n","skplt.metrics.plot_confusion_matrix(y_test.to_list(),\n","                                    y_pred_thresh.tolist(),\n","                                    figsize=(6,6),\n","                                    text_fontsize=14)\n","plt.title(label='Test Confusion Matrix', fontsize=20, pad=17)\n","plt.xlabel('Predicted Label', labelpad=14)\n","plt.ylabel('True Label', labelpad=14)\n","\n","# Save the figure\n","plt.savefig('figures/unbalanced_confusionmatrix.png', dpi=300.0, transparent=True)\n","\n","# Log the confusion matrix\n","experiment.log_image('figures/unbalanced_confusionmatrix.png', name='Test Confusion Matrix')"]},{"cell_type":"markdown","metadata":{},"source":["## End the Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"title":"In [19]:","trusted":false},"outputs":[],"source":["# Save model\n","tf.saved_model.save(model, 'models/unbalanced_model')\n","\n","# Log final model\n","experiment.log_model(name='Final Model (Unbalanced)', \n","                     file_or_folder='models/unbalanced_model')\n","\n","# End Comet.ml experiment\n","experiment.end()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
